# Kubeadm @Centos 7.4 å®‰è£… Kubernetes 1.9.1

[TOC]

## 1. Kubeadmä»‹ç»

kubeadm æ˜¯å®˜æ–¹æä¾›çš„å·¥å…·ï¼Œç”¨äºå¿«é€Ÿå®‰è£…ä¸€ä¸ªæœ€å°è¿è¡Œçš„ Clusterï¼Œå› æ­¤å®‰è£…è¿‡ç¨‹ä¸­ä¸ä¼šå®‰è£…ç›¸å…³çš„ addonsï¼ŒåŒæ—¶ä¹Ÿä¸ä¼šå®‰è£…ç›¸å…³çš„ç½‘ç»œç»„ä»¶ï¼Œä¸»è¦æˆ‘ä»¬è‡ªå·±è°ƒç”¨ `kubectl apply` å‘½ä»¤è¿›è¡Œå®‰è£…å…¼å®¹ CNI æ ‡å‡†çš„ç»„ä»¶ï¼Œä¾‹å¦‚ flannelã€‚å‚è€ƒæ–‡æ¡£ï¼š

*  [Using kubeadm to Create a Cluster](https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/)  ä»‹ç»äº†ä½¿ç”¨ kubeadm å»ºç«‹ä¸€ä¸ªé›†ç¾¤çš„ä¸»è¦æ­¥éª¤
*  [Overview of kubeadm](https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm/) è¯¦ç»†ä»‹ç»äº†å·¥å…·çš„ä½¿ç”¨ç»†èŠ‚

é€šè¿‡ kubeadm å·¥å…·å®‰è£… Clusterï¼Œæœ‰ç‚¹ç±»ä¼¼äº Ceph çš„å®‰è£…æ–¹å¼ã€‚

åœ¨k8s 1.9.x ç‰ˆæœ¬ä¸­ï¼Œkubeadmæ•´ä½“ç‰¹æ€§å·²ç»ä¸º**Beta**ç‰ˆæœ¬ï¼Œé¢„è®¡åœ¨2018å¹´å°†ä¼š**General Availability (GA)**ã€‚

**å…³äºå®‰è£…è¿‡ç¨‹ä¸­çš„é•œåƒé—®é¢˜ï¼š**

> kubeadm ä¸­é»˜è®¤çš„é•œåƒæºæ˜¯ Google Couldçš„åœ°å€ï¼Œå› æ­¤åœ¨å›½å†…å®‰è£…å¦‚æœä¸èƒ½ç¿»å¢™çš„è¯ï¼Œå¯ä»¥å‚è€ƒä¸€ä¸‹æ–‡æ¡£ï¼š[Running kubeadm without an internet connection](https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-init/#running-kubeadm-without-an-internet-connection), HA æ–¹å¼å¯ä»¥å‚è€ƒ [[kubeadm-highavailiability](https://github.com/cookeem/kubeadm-ha/blob/master/README_CN.md#toc0) 1.7.x]ï¼Œç¦»çº¿å®‰è£…è¿‡ç¨‹ä¸­éœ€è¦çš„é•œåƒåˆ—è¡¨ï¼š
>
> | Image Name                               | v1.8 release branch version | v1.9 release branch version |
> | ---------------------------------------- | --------------------------- | --------------------------- |
> | k8s.gcr.io/kube-apiserver-${ARCH}        | v1.8.x                      | v1.9.x                      |
> | k8s.gcr.io/kube-controller-manager-${ARCH} | v1.8.x                      | v1.9.x                      |
> | k8s.gcr.io/kube-scheduler-${ARCH}        | v1.8.x                      | v1.9.x                      |
> | k8s.gcr.io/kube-proxy-${ARCH}            | v1.8.x                      | v1.9.x                      |
> | k8s.gcr.io/etcd-${ARCH}                  | 3.0.17                      | 3.1.10                      |
> | k8s.gcr.io/pause-${ARCH}                 | 3.0                         | 3.0                         |
> | k8s.gcr.io/k8s-dns-sidecar-${ARCH}       | 1.14.5                      | 1.14.7                      |
> | k8s.gcr.io/k8s-dns-kube-dns-${ARCH}      | 1.14.5                      | 1.14.7                      |
> | k8s.gcr.io/k8s-dns-dnsmasq-nanny-${ARCH} | 1.14.5                      | 1.14.7                      |

> å¦‚æœåœ¨é˜¿é‡Œäº‘ä¸Šå®‰è£…ï¼Œä¹Ÿå¯ä»¥é‡‡ç”¨é˜¿é‡Œäº‘æä¾›çš„é•œåƒï¼Œå¯èƒ½é•œåƒåŒæ­¥ä¼šæœ‰æ»åï¼š[é˜¿é‡Œäº‘å¿«é€Ÿéƒ¨ç½²Kubernetes - VPCç¯å¢ƒ](https://yq.aliyun.com/articles/66474) [é˜¿é‡Œäº‘ kubernetes yum ä»“åº“é•œåƒ](https://ieevee.com/tech/2017/09/17/k8s-yum-mirror.html)



## 2. å‡†å¤‡å·¥ä½œ

ä½¿ç”¨ VMWare Fusion å®‰è£… Centos7 è™šæ‹Ÿæœºä¸¤å°ï¼Œç½‘ç»œé‡‡ç”¨NATæ–¹å¼ï¼Œç½‘æ®µä¸º 172.16.132.0/24

172.16.132.10 master node1

172.16.132.11 node2

**required ports **

 **Master node(s)**

| Protocol | Direction | Port Range | Purpose                 |
| -------- | --------- | ---------- | ----------------------- |
| TCP      | Inbound   | 6443*      | Kubernetes API server   |
| TCP      | Inbound   | 2379-2380  | etcd server client API  |
| TCP      | Inbound   | 10250      | Kubelet API             |
| TCP      | Inbound   | 10251      | kube-scheduler          |
| TCP      | Inbound   | 10252      | kube-controller-manager |
| TCP      | Inbound   | 10255      | Read-only Kubelet API   |

 **Worker node(s)**

| Protocol | Direction | Port Range  | Purpose               |
| -------- | --------- | ----------- | --------------------- |
| TCP      | Inbound   | 10250       | Kubelet API           |
| TCP      | Inbound   | 10255       | Read-only Kubelet API |
| TCP      | Inbound   | 30000-32767 | NodePort Services     |

**åœ¨ Master ä¸»æœºä¸Šè®¾ç½®ç›¸å…³æŒ‡ä»¤ï¼š**

```shell
# è®¾ç½®æ—¶åŒº
$ timedatectl list-timezones
$ timedatectl set-timezone Asia/Shanghai

# å®‰è£… lsb å·¥å…·
$ yum install redhat-lsb -y
$ lsb_release -a
LSB Version:	:core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch
Distributor ID:	CentOS
Description:	CentOS Linux release 7.4.1708 (Core) 
Release:	7.4.1708
Codename:	Core

# é…ç½®é™æ€IPåœ°å€
$ vim /etc/sysconfig/network-scripts/ifcfg-ens33
TYPE="Ethernet"
BOOTPROTO="static"   # ä¿®æ”¹ dhcp -> static
IPADDR=172.16.132.10
GATEWAY=172.16.132.2
NETMASK=255.255.255.0
DNS1=172.16.132.2
DEFROUTE="yes"
PEERDNS="yes"
PEERROUTES="yes"
IPV4_FAILURE_FATAL="no"
NAME="ens33"
UUID="018249e8-2e66-41ec-8974-032e1ca47244"
DEVICE="ens33"
ONBOOT="yes"


# é‡å¯ç½‘å¡ç”Ÿæ•ˆ
$ systemctl restart network

# è®¾ç½®DNS
$ vim /etc/resolv.conf
# Generated by NetworkManager
nameserver 172.16.132.2      # vmware è™šæ‹Ÿæœº

# å…³é—­é˜²ç«å¢™
$ systemctl status firewalld
$ systemctl stop firewalld
$ systemctl disable firewalld
Removed symlink /etc/systemd/system/multi-user.target.wants/firewalld.service.
Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service.

# ä»Macæœºå™¨ä¸Šæ·»åŠ è¯ä¹¦
$ ssh-copy-id root@172.16.132.10
The authenticity of host '172.16.132.10 (172.16.132.10)' can't be established.
ECDSA key fingerprint is SHA256:4vwrFA2u0DwO8G0jCN+rqp3A3ZVf1oTIDb+LNG9M334.
Are you sure you want to continue connecting (yes/no)? yes
/usr/local/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed
/usr/local/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys
root@172.16.132.10's password:

Number of key(s) added:        1

Now try logging into the machine, with:   "ssh 'root@172.16.132.10'"
and check to make sure that only the key(s) you wanted were added.


# ç¦ç”¨ selinux
$ setenforce 0
$ vim /etc/selinux/config
SELINUX=disabled

$ cat /etc/hosts
172.16.132.10 node1
172.16.132.11 node2
```



éœ€è¦ç¦ç”¨ IPv6ï¼Œé˜²æ­¢åç»­çš„æ“ä½œç¢°åˆ°IPv6çš„åœ°å€ï¼š

```shell
$ ifconfig -a | grep inet6
        inet6 fe80::211:aff:fe6a:9de4  prefixlen 64  scopeid 0x20
        inet6 ::1  prefixlen 128  scopeid 0x10[host]
        
# add /etc/sysctl.conf
$ cat /etc/sysctl.conf
net.ipv6.conf.all.disable_ipv6 = 1
net.ipv6.conf.default.disable_ipv6 = 1

$ sysctl -p
```



## 3. å®‰è£… Docker

**ä½¿ç”¨Centos 7ä¸­è‡ªå¸¦dockerç‰ˆæœ¬**

```shell
$ yum install -y docker
$ systemctl enable docker && systemctl start docker

$ docker version
Client:
 Version:         1.12.6
 API version:     1.24
 Package version: docker-1.12.6-68.gitec8512b.el7.centos.x86_64
 Go version:      go1.8.3
 Git commit:      ec8512b/1.12.6
 Built:           Mon Dec 11 16:08:42 2017
 OS/Arch:         linux/amd64
 
 
$ docker info
Containers: 0
 Running: 0
 Paused: 0
 Stopped: 0
Images: 0
Server Version: 1.12.6
Storage Driver: devicemapper
 Pool Name: docker-8:3-34809708-pool
 Pool Blocksize: 65.54 kB
 Base Device Size: 10.74 GB
 Backing Filesystem: xfs
 Data file: /dev/loop0
 Metadata file: /dev/loop1
 Data Space Used: 11.8 MB
 Data Space Total: 107.4 GB
 Data Space Available: 14.57 GB
 Metadata Space Used: 581.6 kB
 Metadata Space Total: 2.147 GB
 Metadata Space Available: 2.147 GB
 Thin Pool Minimum Free Space: 10.74 GB
 Udev Sync Supported: true
 Deferred Removal Enabled: true
 Deferred Deletion Enabled: true
 Deferred Deleted Device Count: 0
 Data loop file: /var/lib/docker/devicemapper/devicemapper/data
 WARNING: Usage of loopback devices is strongly discouraged for production use. Use `--storage-opt dm.thinpooldev` to specify a custom block storage device.
 Metadata loop file: /var/lib/docker/devicemapper/devicemapper/metadata
 Library Version: 1.02.140-RHEL7 (2017-05-03)
Logging Driver: journald
Cgroup Driver: systemd     # é»˜è®¤ä¸ºsystemdï¼Œä¸éœ€è¦å•ç‹¬è®¾ç½®ï¼Œå¦åˆ™åœ¨/etc/docker/daemon.jsonä¸­è®¾ç½®
Plugins:
 Volume: local
 Network: host bridge overlay null
Swarm: inactive
Runtimes: docker-runc runc
Default Runtime: docker-runc
Security Options: seccomp selinux
Kernel Version: 3.10.0-693.el7.x86_64
Operating System: CentOS Linux 7 (Core)
OSType: linux
Architecture: x86_64
Number of Docker Hooks: 3
CPUs: 1
Total Memory: 976.3 MiB
Name: master
ID: W4NY:E6NL:NV37:46ME:GYTH:Q3P7:VQKC:ONYH:YOIR:4TRK:6CAO:XBRB
Docker Root Dir: /var/lib/docker
Debug Mode (client): false
Debug Mode (server): false
Registry: https://index.docker.io/v1/
Insecure Registries:
 127.0.0.0/8
Registries: docker.io (secure)
```



> On each of your machines, install Docker. Version v1.12 is recommended, but v1.11, v1.13 and 17.03 are known to work as well. Versions 17.06+ *might work*, but have not yet been tested and verified by the Kubernetes node team.
>
> https://kubernetes.io/docs/setup/independent/install-kubeadm/



å¯é€‰ï¼š **å®‰è£… Docker CEç‰ˆæœ¬** ä¸€èˆ¬ç”¨äºæœ€æ–°ç‰ˆæœ¬éªŒè¯

```
$ yum install -y yum-utils device-mapper-persistent-data lvm2

# æ·»åŠ  repo
$ yum-config-manager \
    --add-repo \
    https://download.docker.com/linux/centos/docker-ce.repo
    
$ yum list docker-ce.x86_64  --showduplicates |sort -r
 * updates: mirrors.163.com
Loading mirror speeds from cached hostfile
Loaded plugins: fastestmirror, langpacks
 * extras: mirrors.aliyun.com
docker-ce.x86_64            17.12.0.ce-1.el7.centos             docker-ce-stable
docker-ce.x86_64            17.09.1.ce-1.el7.centos             docker-ce-stable
docker-ce.x86_64            17.09.0.ce-1.el7.centos             docker-ce-stable
docker-ce.x86_64            17.06.2.ce-1.el7.centos             docker-ce-stable
docker-ce.x86_64            17.06.1.ce-1.el7.centos             docker-ce-stable
docker-ce.x86_64            17.06.0.ce-1.el7.centos             docker-ce-stable
docker-ce.x86_64            17.03.2.ce-1.el7.centos             docker-ce-stable
docker-ce.x86_64            17.03.1.ce-1.el7.centos             docker-ce-stable
docker-ce.x86_64            17.03.0.ce-1.el7.centos             docker-ce-stable
 * base: mirrors.aliyun.com
Available Packages

# å®‰è£… docker-ce-17.03.2 æˆ–è€… ä½¿ç”¨ centos é»˜è®¤æ”¯æŒçš„ç‰ˆæœ¬
# $ yum makecache fast
#$ yum install -y --setopt=obsoletes=0 \
#  docker-ce-17.03.2.ce-1.el7.centos \
#  docker-ce-selinux-17.03.2.ce-1.el7.centos


# docker  1.12.6 ä¸­ï¼Œä¸éœ€è¦è®¾ç½®è¯¥å‚æ•° cmd ä¸­å·²ç»åŒ…å«
# ä½¿ç”¨ç³»ç»Ÿé»˜è®¤æ”¯æŒçš„æ–¹æ³•
# Note: Make sure that the cgroup driver used by kubelet is the same as the one used by Docker. # To ensure compatability you can either update Docker, like so:
$ mkdir -p /etc/docker/
$ cat << EOF > /etc/docker/daemon.json
{
  "exec-opts": ["native.cgroupdriver=systemd"]
}
EOF

$ cat <<EOF >  /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF
sysctl --system
```



## 4. å®‰è£… kubeadm å’Œ kubelet 

**è®¾ç½®å®˜æ–¹ Repo**

```shell
$ cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
EOF
setenforce 0

$ yum install -y kubelet kubeadm kubectl
```



**å®‰è£… kubelete å’Œ kubeadm**

å®‰è£… kubeadm/kubectl/kubernetes-cni ä¸‰ä¸ªä¸»è¦ç¨‹åºï¼Œå®‰è£…ä¸¤ä¸ªä¾èµ–åŒ…kubernetes-cni å’Œ socat

ç”±äº socat å®‰è£…ä¸éœ€è¦ç¿»å¢™ï¼Œå¦‚æœç¿»å¢™äº†è¿˜å¯èƒ½å­˜åœ¨å®‰è£…çš„é—®é¢˜ï¼Œå»ºè®®å…ˆå®‰è£… socat åå†ç¿»å¢™

```shell
$ yum install -y socat
```



**ä»¥ä¸‹è¿‡ç¨‹éœ€è¦ç§‘å­¦ä¸Šç½‘**

```shell
$ yum install -y kubelet kubeadm kubectl
Loaded plugins: fastestmirror, langpacks
Loading mirror speeds from cached hostfile
 * base: mirrors.aliyun.com
 * extras: mirrors.aliyun.com
 * updates: mirrors.163.com
Resolving Dependencies
--> Running transaction check
---> Package kubeadm.x86_64 0:1.9.1-0 will be installed
--> Processing Dependency: kubernetes-cni for package: kubeadm-1.9.1-0.x86_64
---> Package kubectl.x86_64 0:1.9.1-0 will be installed
---> Package kubelet.x86_64 0:1.9.1-0 will be installed
--> Processing Dependency: socat for package: kubelet-1.9.1-0.x86_64
--> Running transaction check
---> Package kubernetes-cni.x86_64 0:0.6.0-0 will be installed
---> Package socat.x86_64 0:1.7.3.2-2.el7 will be installed
--> Finished Dependency Resolution

Dependencies Resolved

 Package   Arch       Version    Repository       Size
=========================================================
Installing:
 kubeadm  x86_64     1.9.1-0     kubernetes          16 M
 kubectl  x86_64     1.9.1-0     kubernetes          8.9 M
 kubelet  x86_64     1.9.1-0     kubernetes          17 M
Installing for dependencies:
 kubernetes-cni  x86_64   0.6.0-0        kubernetes        8.6 M
 socat           x86_64   1.7.3.2-2.el7  base             290 k

Transaction Summary
=========================================================
Install  3 Packages (+2 Dependent packages)

Total size: 51 M
Installed size: 274 M
Downloading packages:
warning: /var/cache/yum/x86_64/7/kubernetes/packages/cec192f6a1a3a90321f0458d336dd56ccbe78f2a47b33bfd6e8fd78151fa3326-kubelet-1.9.1-0.x86_64.rpm: Header V4 RSA/SHA1 Signature, key ID 3e1ba8d5: NOKEY
Retrieving key from https://packages.cloud.google.com/yum/doc/yum-key.gpg
Importing GPG key 0xA7317B0F:
 Userid     : "Google Cloud Packages Automatic Signing Key <gc-team@google.com>"
 Fingerprint: d0bc 747f d8ca f711 7500 d6fa 3746 c208 a731 7b0f
 From       : https://packages.cloud.google.com/yum/doc/yum-key.gpg
Retrieving key from https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
Importing GPG key 0x3E1BA8D5:
 Userid     : "Google Cloud Packages RPM Signing Key <gc-team@google.com>"
 Fingerprint: 3749 e1ba 95a8 6ce0 5454 6ed2 f09c 394c 3e1b a8d5
 From       : https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
Running transaction check
Running transaction test
Transaction test succeeded
Running transaction
  Installing : kubectl-1.9.1-0.x86_64                                 1/5
  Installing : socat-1.7.3.2-2.el7.x86_64                             2/5
  Installing : kubernetes-cni-0.6.0-0.x86_64                          3/5
  Installing : kubelet-1.9.1-0.x86_64                                 4/5
  Installing : kubeadm-1.9.1-0.x86_64                                 5/5
  
  Verifying  : kubelet-1.9.1-0.x86_64                                 1/5
  Verifying  : kubernetes-cni-0.6.0-0.x86_64                          2/5
  Verifying  : socat-1.7.3.2-2.el7.x86_64                             3/5
  Verifying  : kubeadm-1.9.1-0.x86_64                                 4/5
  Verifying  : kubectl-1.9.1-0.x86_64                                 5/5

Installed:
  kubeadm.x86_64 0:1.9.1-0                
  kubectl.x86_64 0:1.9.1-0                
  kubelet.x86_64 0:1.9.1-0

Dependency Installed:
  kubernetes-cni.x86_64 0:0.6.0-0                                           
  socat.x86_64 0:1.7.3.2-2.el7

Complete!
```


ä½¿ç”¨ kubeadméªŒè¯ä¸€ä¸‹ç‰ˆæœ¬ä¿¡æ¯ï¼š

```shell
$ kubeadm version
kubeadm version: &version.Info{Major:"1", Minor:"9", GitVersion:"v1.9.1", GitCommit:"3a1c9449a956b6026f075fa3134ff92f7d55f812", GitTreeState:"clean", BuildDate:"2018-01-04T11:40:06Z", GoVersion:"go1.9.2", Compiler:"gc", Platform:"linux/amd64"}

$ systemctl enable kubelet
Created symlink from /etc/systemd/system/multi-user.target.wants/kubelet.service to /etc/systemd/system/kubelet.service

# RHEL/CentOS 7 have reported issues with traffic being routed incorrectly due to iptables being bypassed
$ cat <<EOF >  /etc/sysctl.d/k8s.conf
# ä¸å¼€å¯ IPv6ï¼Œå› æ­¤æ³¨é‡Šæ‰
# net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF

# é…ç½®ç”Ÿæ•ˆ
$ sysctl --system
```

ç”±äºè¿˜æœªé‡‡ç”¨kubeamè¿›è¡Œé›†ç¾¤åˆå§‹åŒ–ï¼Œå› æ­¤ç°åœ¨å¯åŠ¨ kubelet æœåŠ¡ä¼šæŠ¥é”™ï¼Œå¯ä»¥ä½¿ç”¨å‘½ä»¤ `systemctl status kubelet` å’Œ  `tail -f /var/log/messages`æŸ¥çœ‹ï¼Œç›®å‰ä¸ºæ­¢å¯ä»¥å¿½ç•¥æŠ¥é”™ä¿¡æ¯ï¼Œå¤§è‡´é”™è¯¯å¦‚ä¸‹ï¼š

```shell
 .....
 error: unable to load client CA file /etc/kubernetes/pki/ca.crt: open /etc/kubernetes/pki/ca.crt: no such file or directory**
 .....
```



**è®¾ç½® Kubelete Swap é€‰é¡¹**

Kubernetes 1.8å¼€å§‹è¦æ±‚å…³é—­ç³»ç»Ÿçš„Swapï¼Œå¦‚æœä¸å…³é—­ï¼Œé»˜è®¤é…ç½®ä¸‹kubeletå°†æ— æ³•å¯åŠ¨ã€‚å¯ä»¥é€šè¿‡kubeletçš„å¯åŠ¨å‚æ•°`--fail-swap-on=false`æ›´æ”¹è¿™ä¸ªé™åˆ¶ã€‚

> **å…¨å±€å…³é—­ï¼š**
> å…³é—­ç³»ç»Ÿçš„Swapæ–¹æ³•å¦‚ä¸‹:
>
> ```
> swapoff -a
> ```
>
> ä¿®æ”¹ /etc/fstab æ–‡ä»¶ï¼Œæ³¨é‡Šæ‰ SWAP çš„è‡ªåŠ¨æŒ‚è½½ï¼Œä½¿ç”¨`free -m`ç¡®è®¤swapå·²ç»å…³é—­ã€‚ > swappinesså‚æ•°è°ƒæ•´ï¼Œä¿®æ”¹/etc/sysctl.d/k8s.confæ·»åŠ ä¸‹é¢ä¸€è¡Œï¼š
>
> ```
> vm.swappiness=0
> ```
>
> æ‰§è¡Œ`sysctl -p /etc/sysctl.d/k8s.conf`ä½¿ä¿®æ”¹ç”Ÿæ•ˆã€‚

å› ä¸ºæµ‹è¯•ä¸»æœºä¸Šè¿˜è¿è¡Œå…¶ä»–æœåŠ¡ï¼Œå…³é—­swapå¯èƒ½ä¼šå¯¹å…¶ä»–æœåŠ¡äº§ç”Ÿå½±å“ï¼Œæ‰€ä»¥è¿™é‡Œä¿®æ”¹kubeletçš„å¯åŠ¨å‚æ•° `--fail-swap-on=false` å»æ‰è¿™ä¸ªé™åˆ¶ã€‚ä¿®æ”¹ `/etc/systemd/system/kubelet.service.d/10-kubeadm.conf`ï¼ŒåŠ å…¥ï¼š

```shell
Environment="KUBELET_EXTRA_ARGS=--fail-swap-on=false"

$ systemctl daemon-reload
```

kubelete çš„é…ç½®æ–‡ä»¶å…¨éƒ¨å†…å®¹å¦‚ä¸‹ï¼š
```shell
$ cat /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
[Service]
Environment="KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf"
Environment="KUBELET_SYSTEM_PODS_ARGS=--pod-manifest-path=/etc/kubernetes/manifests --allow-privileged=true"
Environment="KUBELET_NETWORK_ARGS=--network-plugin=cni --cni-conf-dir=/etc/cni/net.d --cni-bin-dir=/opt/cni/bin"
Environment="KUBELET_DNS_ARGS=--cluster-dns=10.96.0.10 --cluster-domain=cluster.local"
Environment="KUBELET_AUTHZ_ARGS=--authorization-mode=Webhook --client-ca-file=/etc/kubernetes/pki/ca.crt"
Environment="KUBELET_CADVISOR_ARGS=--cadvisor-port=0"
Environment="KUBELET_CGROUP_ARGS=--cgroup-driver=systemd"
Environment="KUBELET_CERTIFICATE_ARGS=--rotate-certificates=true --cert-dir=/var/lib/kubelet/pki"
# add for this time ==================================
Environment="KUBELET_EXTRA_ARGS=--fail-swap-on=false"
ExecStart=
ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_SYSTEM_PODS_ARGS $KUBELET_NETWORK_ARGS $KUBELET_DNS_ARGS $KUBELET_AUTHZ_ARGS $KUBELET_CADVISOR_ARGS $KUBELET_CGROUP_ARGS $KUBELET_CERTIFICATE_ARGS $KUBELET_EXTRA_ARGS

```



**å¯åŠ¨ Kubelete æœåŠ¡**

```shell
$ systemctl daemon-reload
$ systemctl start kubelet
```



ä»¥ä¸Šæ“ä½œå®Œæˆåï¼Œå¯ä»¥ä½¿ç”¨ Vmware çš„ `Take Snapshot` åˆ›å»ºä¸€ä¸ªå¿«ç…§ï¼Œç„¶åå…³é—­è™šæ‹Ÿæœºä½¿ç”¨ `Create Full Clone` åŠŸèƒ½å°†æˆ‘ä»¬å®‰è£…è™šæ‹Ÿæœº Clone æˆ Node èŠ‚ç‚¹ï¼Œç„¶åæ ¹æ®éœ€è¦ä¿®æ”¹IPåœ°å€ç­‰ä¿¡æ¯å³å¯ï¼›åœ¨é˜¿é‡Œäº‘çš„ç¯å¢ƒä¸­æˆ‘ä»¬ä¸€èˆ¬æ˜¯å°†è¿™ä¸ªå…·å¤‡äº†ä¸€å®šç¯å¢ƒçš„ç³»ç»Ÿä¿å­˜ä¸ºé•œåƒï¼Œä»¥åæ‰©å®¹çš„æ—¶å€™å¯ä»¥æ–¹ä¾¿ä½¿ç”¨ï¼Œä¸å†éœ€è¦ä»å¤´å®‰è£…ã€‚



## 5. åˆå§‹åŒ–é›†ç¾¤

Kubernetes 1.8å¼€å§‹è¦æ±‚å…³é—­ç³»ç»Ÿçš„Swapï¼Œå¦‚æœä¸å…³é—­ï¼Œé»˜è®¤é…ç½®ä¸‹kubeletå°†æ— æ³•å¯åŠ¨ï¼Œæœ¬å®‰è£…è¿‡ç¨‹ä¸­æˆ‘ä»¬ä¼šé‡‡ç”¨å…ˆå¿½ç•¥åé¢å†è®¾ç½®çš„æ–¹æ³•ï¼Œæ‰€ä»¥é‡‡ç”¨å‚æ•°  `--ignore-preflight-errors=Swap` å¿½ç•¥è¿™ä¸ªé”™è¯¯ã€‚å¯¹äº POD Network æˆ‘ä»¬é‡‡ç”¨ Flannelï¼ŒFlannel é»˜è®¤è®¾ç½®çš„ç½‘æ®µä¸º `10.244.0.0./16`ï¼Œå› æ­¤æˆ‘ä»¬åœ¨ init å‘½ä»¤ä¸­ä½¿ç”¨  `--pod-network-cidr=10.244.0.0/16` æ¥æŒ‡å®šã€‚å½“ç„¶ `kubeadm init` å‘½ä»¤è¡Œä¸­çš„å‚æ•°ä¹Ÿå¯ä»¥ä½¿ç”¨é…ç½®æ–‡ä»¶æ¥é…ç½®ï¼Œå‚è§ [Configureation file](https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-init/#config-file) ç« èŠ‚ã€‚

init è¿‡ç¨‹ä¸­éœ€è¦ç§‘å­¦ä¸Šç½‘ï¼Œï¼ˆä¸éœ€è¦ç¿»å¢™å®‰è£…æ–¹å¼è§æœ¬æ–‡çš„ç¬¬ä¸€ç« èŠ‚ï¼‰å¦‚æœé¡ºåˆ©çš„è¯ï¼Œåˆ™å¯ä»¥çœ‹åˆ°ä»¥ä¸‹è¾“å‡ºï¼š

```shell
$ kubeadm init   --kubernetes-version=v1.9.1   --pod-network-cidr=10.244.0.0/16   --apiserver-advertise-address=172.16.132.10 --ignore-preflight-errors=Swap > install.log 2>&1 # å®‰è£…çš„ä¿¡æ¯
[init] Using Kubernetes version: v1.9.1
[init] Using Authorization modes: [Node RBAC]
[preflight] Running pre-flight checks.
	[WARNING Swap]: running with swap on is not supported. Please disable swap
	[WARNING FileExisting-crictl]: crictl not found in system path
[preflight] Starting the kubelet service
[certificates] Generated ca certificate and key.
[certificates] Generated apiserver certificate and key.
[certificates] apiserver serving cert is signed for DNS names [node1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 172.16.132.10]
[certificates] Generated apiserver-kubelet-client certificate and key.
[certificates] Generated sa key and public key.
[certificates] Generated front-proxy-ca certificate and key.
[certificates] Generated front-proxy-client certificate and key.
[certificates] Valid certificates and keys now exist in "/etc/kubernetes/pki"
[kubeconfig] Wrote KubeConfig file to disk: "admin.conf"
[kubeconfig] Wrote KubeConfig file to disk: "kubelet.conf"
[kubeconfig] Wrote KubeConfig file to disk: "controller-manager.conf"
[kubeconfig] Wrote KubeConfig file to disk: "scheduler.conf"
[controlplane] Wrote Static Pod manifest for component kube-apiserver to "/etc/kubernetes/manifests/kube-apiserver.yaml"
[controlplane] Wrote Static Pod manifest for component kube-controller-manager to "/etc/kubernetes/manifests/kube-controller-manager.yaml"
[controlplane] Wrote Static Pod manifest for component kube-scheduler to "/etc/kubernetes/manifests/kube-scheduler.yaml"
[etcd] Wrote Static Pod manifest for a local etcd instance to "/etc/kubernetes/manifests/etcd.yaml"
[init] Waiting for the kubelet to boot up the control plane as Static Pods from directory "/etc/kubernetes/manifests".
[init] This might take a minute or longer if the control plane images have to be pulled.

[apiclient] All control plane components are healthy after 31.501968 seconds
[uploadconfig]Â Storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace
[markmaster] Will mark node node1 as master by adding a label and a taint
[markmaster] Master node1 tainted and labelled with key/value: node-role.kubernetes.io/master=""
[bootstraptoken] Using token: 047b97.bf92a2b4e89d9e0b
[bootstraptoken] Configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
[bootstraptoken] Configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
[bootstraptoken] Configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
[bootstraptoken] Creating the "cluster-info" ConfigMap in the "kube-public" namespace
[addons] Applied essential addon: kube-dns
[addons] Applied essential addon: kube-proxy

Your Kubernetes master has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

You can now join any number of machines by running the following on each node
as root:

  kubeadm join --token 047b97.bf92a2b4e89d9e0b 172.16.132.10:6443 --discovery-token-ca-cert-hash sha256:f24acbcecbfa71ca8cae8367d4ad807d472107a8fca0280ff0624f503b7f93f9

$  docker images
REPOSITORY                                               TAG                 IMAGE ID            CREATED             SIZE
gcr.io/google_containers/kube-apiserver-amd64            v1.9.1              e313a3e9d78d        10 days ago         210.4 MB
gcr.io/google_containers/kube-scheduler-amd64            v1.9.1              677911f7ae8f        10 days ago         62.7 MB
gcr.io/google_containers/kube-controller-manager-amd64   v1.9.1              4978f9a64966        10 days ago         137.8 MB
gcr.io/google_containers/kube-proxy-amd64                v1.9.1              e470f20528f9        10 days ago         109.1 MB
gcr.io/google_containers/etcd-amd64                      3.1.10              1406502a6459        4 months ago        192.7 MB
gcr.io/google_containers/pause-amd64                     3.0                 99e59f495ffa        20 months ago       746.9 kB

```



>  å®‰è£…ä¸­é‡åˆ°çš„ä¸¤ä¸ªé—®é¢˜è§£é‡Šï¼š

```shell
	[WARNING Swap]: running with swap on is not supported. Please disable swap
	 ---- æˆ‘ä»¬å‰é¢å·²ç»é€šè¿‡ kubelet çš„å‘½ä»¤è¡Œæ¥æŒ‡å®š
	[WARNING FileExisting-crictl]: crictl not found in system path
	----  crictl å·¥å…·æ˜¯goå¼€å‘çš„å·¥å…·åŒ…ï¼Œéœ€è¦å•ç‹¬å®‰è£…ï¼Œä½†æ˜¯å®‰è£…æˆåŠŸåä¹Ÿé‡åˆ°äº†ä¸èƒ½è§£å†³çš„é—®é¢˜ï¼Œå› æ­¤å¯ä»¥å¿½ç•¥è¿™ä¸ªé”™è¯¯
```

å¦‚æœæŒ‰ç…§è¿‡ç¨‹ä¸­é‡åˆ°äº†å…¶ä»–é—®é¢˜ï¼Œå¯ä»¥ä½¿ç”¨ `kubeadm reset`è¿›è¡Œæ¸…é™¤ã€‚



**è®¾ç½®ç”¨æˆ·çš„ kubectl ç¯å¢ƒ**

```shell
$ mkdir -p $HOME/.kube
$ cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
$ chown $(id -u):$(id -g) $HOME/.kube/config
  
  
 # è®¾ç½® kubectlè¡¥å…¨
 $ kubectl completion bash > ~/.kube/completion.bash.inc
 $ cat ~/.bash_profile
 .....
 source ~/.kube/completion.bash.inc
 .....
 
 $ source ~/.bash_profile
```



**è·å–é›†ç¾¤çš„çŠ¶æ€**

```shell
$ kubectl get cs
NAME                 STATUS    MESSAGE              ERROR
scheduler            Healthy   ok
controller-manager   Healthy   ok
etcd-0               Healthy   {"health": "true"}
```



## 6. å®‰è£… Pod Network

æœ¬æ–‡é€‰æ‹© Flannel ä½œä¸º Pod Networkï¼Œé»˜è®¤ç½‘æ®µå·²ç»é€šè¿‡ init å‚æ•° `--pod-network-cidr=10.244.0.0/16`æŒ‡å®šã€‚ç”±äº kube-flannel.yml ä¸­ä»¥ DaemonSet æ–¹å¼è¿è¡Œçš„ï¼Œèƒ½å¤Ÿä¿è¯æ¯ä¸ªæ–°åŠ å¦‚ Node è‡ªåŠ¨è¿è¡Œ Flannelï¼Œ å› æ­¤åªéœ€è¦åœ¨ Master èŠ‚ç‚¹ä¸Šè¿è¡Œå³å¯ã€‚

```shell
$ mkdir -p ~/k8s/
$ cd ~/k8s
$ wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
$ kubectl apply -f  kube-flannel.yml
clusterrole "flannel" created
clusterrolebinding "flannel" created
serviceaccount "flannel" created
configmap "kube-flannel-cfg" created
daemonset "kube-flannel-ds" created
```

å®‰è£…å®Œæˆåä¼šåˆ›å»º cni0 ä¸ flannel.1 ä¸¤ä¸ªè®¾å¤‡ï¼š

```shell
6: flannel.1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UNKNOWN
    link/ether 9e:a4:0e:29:5c:cf brd ff:ff:ff:ff:ff:ff
    inet 10.244.0.0/32 scope global flannel.1
       valid_lft forever preferred_lft forever
    inet6 fe80::9ca4:eff:fe29:5ccf/64 scope link
       valid_lft forever preferred_lft forever
       
7: cni0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UP qlen 1000
    link/ether 0a:58:0a:f4:00:01 brd ff:ff:ff:ff:ff:ff
    inet 10.244.0.1/24 scope global cni0
       valid_lft forever preferred_lft forever
    inet6 fe80::c83d:76ff:fe49:6232/64 scope link
       valid_lft forever preferred_lft forever


$ brctl show
bridge name	bridge id		STP enabled	interfaces
cni0		8000.0a580af40001	no		veth7f53d148
docker0		8000.0242eed2f41f	no
virbr0		8000.52540096686f	yes		virbr0-nic

```



å¦‚æœè¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æ¸…é™¤è®¾ç½®çš„ç›¸å…³ç½‘ç»œè®¾å¤‡ä¸è¿è¡Œæ—¶å€™çš„é…ç½®æ–‡ä»¶ï¼š

```shell
$ ifconfig cni0 down
$ ip link delete cni0
$ ifconfig flannel.1 down
$ ip link delete flannel.1
$ rm -rf /var/lib/cni/
```



é»˜è®¤æƒ…å†µä¸‹ Master èŠ‚ç‚¹ä¸è¿›è¡Œ Pod è°ƒåº¦ï¼Œä¸ºäº†æ–¹ä¾¿æµ‹è¯•ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤è®© Master å‚ä¸è°ƒåº¦ï¼š

```shell
$ kubectl taint nodes --all node-role.kubernetes.io/master-
```



æµ‹è¯• dns å’Œ  nginx

![](https://www.kubernetes.org.cn/img/2016/10/20161028145516.jpg)

```shell
# curl å·¥å…·
$ kubectl run curl --image=radial/busyboxplus:curl -i --tty
$ nslookup kubernetes.default
Server:    10.96.0.10
Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local

Name:      kubernetes.default
Address 1: 10.96.0.1 kubernetes.default.svc.cluster.local


$ cat nginx-deployment.yaml
apiVersion: apps/v1beta2 # for versions before 1.8.0 use apps/v1beta1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  selector:
    matchLabels:
      app: nginx
  replicas: 2 # tells deployment to run 2 pods matching the template
  template: # create pods using pod definition in this template
    metadata:
      # unlike pod-nginx.yaml, the name is not included in the meta data as a unique name is
      # generated from the deployment name
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.7.9
        ports:
        - containerPort: 80

$ kubectl apply -f nginx-deployment.yaml
# å¯¼å‡ºæœåŠ¡
$ kubectl expose deployment nginx-deployment --port=80 --target-port=80

```



## 7. åˆå§‹åŒ–Nodes

å’Œ master node ä¸Šä¸€æ ·è®¾ç½® kubele ç›¸å…³å‚æ•°ï¼ˆ`KUBELET_EXTRA_ARGS=--fail-swap-on=false`ï¼‰ï¼›

**ä¿æŒç§‘å­¦ä¸Šç½‘ï¼š**

```
$ kubeadm join --token 047b97.bf92a2b4e89d9e0b 172.16.132.10:6443 --discovery-token-ca-cert-hash sha256:f24acbcecbfa71ca8cae8367d4ad807d472107a8fca0280ff0624f503b7f93f9 --ignore-preflight-errors=Swap

[preflight] Running pre-flight checks.
	[WARNING FileExisting-crictl]: crictl not found in system path
[discovery] Trying to connect to API Server "172.16.132.10:6443"
[discovery] Created cluster-info discovery client, requesting info from "https://172.16.132.10:6443"
[discovery] Requesting info from "https://172.16.132.10:6443" again to validate TLS against the pinned public key
[discovery] Cluster info signature and contents are valid and TLS certificate validates against pinned roots, will use API Server "172.16.132.10:6443"
[discovery] Successfully established connection with API Server "172.16.132.10:6443"

This node has joined the cluster:
* Certificate signing request was sent to master and a response
  was received.
* The Kubelet was informed of the new secure connection details.

Run 'kubectl get nodes' on the master to see this node join the cluster.

```



åœ¨ Master èŠ‚ç‚¹ä¸Šäº§ç”Ÿè¯ä¹¦å¹¶Copy Configåˆ°NodeèŠ‚ç‚¹ä¸Šï¼š

```shell
$ ssh-keygen   # ä¸€è·¯å›è½¦
$ ssh-copy-id root@172.16.132.11

# copy é…ç½®æ–‡ä»¶åˆ° node2ä¸Š
$ scp /etc/kubernetes/admin.conf root@172.16.132.11:/root/.kube/config
```



**ç§»é™¤ Node**

```shell
$ kubectl drain node2 --delete-local-data --force --ignore-daemonsets
$ kubectl delete node node2

# æ¸…ç†
$ kubeadm reset
$ ifconfig cni0 down
$ ip link delete cni0
$ ifconfig flannel.1 down
$ ip link delete flannel.1
$ rm -rf /var/lib/cni/
```





## 8. å®‰è£… Addons

### DashBoard

```shell
$ wget https://raw.githubusercontent.com/kubernetes/dashboard/v1.8.1/src/deploy/recommended/kubernetes-dashboard.yaml

spec:
  type: NodePort  # add to nodeport
  ports:
    - port: 8443
      targetPort: 8443
  selector:
    k8s-app: kubernetes-dashboard
    
$ kubectl create -f kubernetes-dashboard.yaml

$ cat kubernetes-dashboard-admin.rbac.yaml
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    k8s-app: kubernetes-dashboard
  name: kubernetes-dashboard-admin
  namespace: kube-system

---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: kubernetes-dashboard-admin
  labels:
    k8s-app: kubernetes-dashboard
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: kubernetes-dashboard-admin
  namespace: kube-system

# kubernetes-dashboard.yamlæ–‡ä»¶ä¸­çš„ServiceAccount kubernetes-dashboardåªæœ‰ç›¸å¯¹è¾ƒå°çš„æƒé™ï¼Œå› æ­¤ 
# åˆ›å»ºä¸€ä¸ªkubernetes-dashboard-adminçš„ServiceAccountå¹¶æˆäºˆé›†ç¾¤adminçš„æƒé™

$ kubectl create -f kubernetes-dashboard-admin.rbac.yaml
serviceaccount "kubernetes-dashboard-admin" created
clusterrolebinding "kubernetes-dashboard-admin" created

$ kubectl -n kube-system get secret | grep kubernetes-dashboard-admin
kubernetes-dashboard-admin-token-tszj5           kubernetes.io/service-account-token   3         20s

$ kubectl describe -n kube-system secret/kubernetes-dashboard-admin-token-tszj5
kubectl describe -n kube-system secret/kubernetes-dashboard-admin-token-tszj5
Name:         kubernetes-dashboard-admin-token-tszj5
Namespace:    kube-system
Labels:       <none>
Annotations:  kubernetes.io/service-account.name=kubernetes-dashboard-admin
              kubernetes.io/service-account.uid=dd1a582a-f9cd-11e7-85ec-000c2975be81

Type:  kubernetes.io/service-account-token

Data
====
ca.crt:     1025 bytes
namespace:  11 bytes
token:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJrdWJlcm5ldGVzLWRhc2hib2FyZC1hZG1pbi10b2tlbi10c3pqNSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJrdWJlcm5ldGVzLWRhc2hib2FyZC1hZG1pbiIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6ImRkMWE1ODJhLWY5Y2QtMTFlNy04NWVjLTAwMGMyOTc1YmU4MSIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlLXN5c3RlbTprdWJlcm5ldGVzLWRhc2hib2FyZC1hZG1pbiJ9.iuqjGsXy9zohzCDLSCpd4RqUyFptSZ_Al8qEpGb_D46Gfscb8DvV24qLR6QF5ejZKh_3Oe4g42GRROLsy_he8Exlxs86YDA5505QptNMDcNOqJqvlk6y8hovLl8gIu6K70ND4q_i9pIxWLDOOUuYLuDO1re3Z0rUa0jZimXiayBXUjuzbJJYYlHL9SREIjxr4y1FTsFFnbZESCYmMNKcQSwhYyTrSyPA8XiiUm_k4aYVtvWqo84nRyxreZ7DH6Zg7YT57oy8DqXHC-GNXFGj7tmDFWzih1GFvTuFp0zqhkjtS1ZAFsSNLIvIwBhg7Aj-6LyDBE4RSUOJg5UiH2trYA
```

æŸ¥è¯¢ dashboard æš´éœ²å‡ºæ¥çš„ NodePortï¼Œå¹¶ä½¿ç”¨ä¸Šå›¾çš„ `token` ä¿¡æ¯è¾“å…¥ï¼š

```shell
$ kubectl get service -n kube-system
NAME                   TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)         AGE
kube-dns               ClusterIP   10.96.0.10      <none>        53/UDP,53/TCP   2h
kubernetes-dashboard   NodePort    10.111.165.62   <none>        443:31290/TCP   5m

```

åœ¨æµè§ˆå™¨ä¸Šè¾“å…¥ https://172.16.132.10:31290, é€‰æ‹©å¿½ç•¥è¯ä¹¦ï¼Œç„¶åè¾“å…¥ Token æ—¢å¯ä»¥è®¿é—®ã€‚



### Heapster

Heapsterä¸ºé›†ç¾¤æ·»åŠ ä½¿ç”¨ç»Ÿè®¡å’Œç›‘æ§åŠŸèƒ½ï¼Œä¸ºDashboardæ·»åŠ ä»ªè¡¨ç›˜ã€‚ ä½¿ç”¨InfluxDBåšä¸ºHeapsterçš„åç«¯å­˜å‚¨ã€‚

```shell
$ mkdir -p ~/k8s/heapster
$ cd ~/k8s/heapster
$ wget https://raw.githubusercontent.com/kubernetes/heapster/master/deploy/kube-config/influxdb/grafana.yaml
$ wget https://raw.githubusercontent.com/kubernetes/heapster/master/deploy/kube-config/rbac/heapster-rbac.yaml
$ wget https://raw.githubusercontent.com/kubernetes/heapster/master/deploy/kube-config/influxdb/heapster.yaml
$ wget https://raw.githubusercontent.com/kubernetes/heapster/master/deploy/kube-config/influxdb/influxdb.yaml

# ä¿®æ”¹ grafana å¯¼å‡ºçš„ service
$ cat grafana.yaml
....
spec:
  type: NodePort
  ports:
  - port: 80
    targetPort: 3000
  selector:
    k8s-app: grafana
.....
$ kubectl create -f ./

$ kubectl get service -n kube-system
NAME                   TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)         AGE
....
monitoring-grafana     NodePort    10.103.229.66   <none>        80:32447/TCP    18m
...
```

ä½¿ç”¨ http://172.16.132.10:32447/?orgId=1 åˆ™å¯ä»¥çœ‹åˆ° Grafana çš„ç•Œé¢ï¼Œå¯ä»¥é€šè¿‡ğŸ“ˆæ¥æŸ¥çœ‹é›†ç¾¤ä¸­çš„å„ç±»èµ„æºä¿¡æ¯ã€‚

## 9. å®‰è£…è¿‡ç¨‹ä¸­é‡åˆ°çš„é”™è¯¯

`crictl not found in system path` https://github.com/kubernetes-incubator/cri-toolsï¼Œéœ€è¦è‡ªå·±ç¼–è¯‘å®‰è£…

```shell
$ wget https://dl.google.com/go/go1.9.2.linux-amd64.tar.gz
$ tar -C /usr/local -xzf go1.9.2.linux-amd64.tar.gz
$ export PATH=$PATH:/usr/local/go/bin
$ go version
go version go1.9.2 linux/amd64
$ yum install git -y
$ mkdir -p $HOME/go/src
$ export GOPATH=$HOME/go
$ go get github.com/kubernetes-incubator/cri-tools
$ cd $GOAPTH/src/github.com/kubernetes-incubator/cri-toolscri-tools/ && make
$ cp $GOPATH/bin/crictl /usr/local/bin
```

```
$ kubeadm init   --kubernetes-version=v1.9.1   --pod-network-cidr=10.0.0.0/16   --apiserver-advertise-address=172.16.132.10
[init] Using Kubernetes version: v1.9.1
[init] Using Authorization modes: [Node RBAC]
[preflight] Running pre-flight checks.
[preflight] Some fatal errors occurred:
	[ERROR Swap]: running with swap on is not supported. Please disable swap
	[ERROR CRI]: unable to check if the container runtime at "/var/run/dockershim.sock" is running: exit status 1
[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`
```



å¦‚æœå®‰è£…äº† crictlï¼Œå¯èƒ½ä¼šæŠ¥ä¸€ä¸‹é”™è¯¯   å‚è§ https://github.com/kubernetes-incubator/cri-tools/issues/153

```
$ kubeadm init   --kubernetes-version=v1.9.1   --pod-network-cidr=10.0.0.0/16   --apiserver-advertise-address=172.16.132.10 --ignore-preflight-errors=Swap
[init] Using Kubernetes version: v1.9.1
[init] Using Authorization modes: [Node RBAC]
[preflight] Running pre-flight checks.
[preflight] Some fatal errors occurred:
	[ERROR CRI]: unable to check if the container runtime at "/var/run/dockershim.sock" is running: exit status 1
[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`
```



```shell
$ crictl ps

2018/01/10 11:16:54 grpc: addrConn.resetTransport failed to create client transport: connection error: desc = "transport: dial unix /var/run/dockershim.sock: connect: no such file or directory"; Reconnecting to {/var/run/dockershim.sock <nil>}

FATA[0000] listing containers failed: rpc error: code = Unavailable desc = grpc: the connection is unavailable

$ crictl --version

crictl version 1.0.0-alpha.0

```

> From https://github.com/kubernetes-incubator/cri-tools/issues/153
>
> CRI is complaining about the lack of the shim sock, which gets checked during `kubeadm init`preflight: `[ERROR CRI]: unable to check if the container runtime at "/var/run/dockershim.sock" is running: exit status 1`. **I don't think this is crictl because kubeadm still complains about it even without crictl installed.** FYI, CRI is a kubelet concept which is exposed as a JSON API, crictl/cri-tools is just a CLI to access kubelet's CRI API.
>
> Also, kubeadm only warns with the lack of crictl, but doesn't require it. So, the additional dependencies only come into play when you want to use a different container runtime interface other than the dockershim that ships with kubelet. This is where you might use cri-o (formerly ocid), which must be manually built and additionally depends on runc.
>
> Aside: on centos 7, [runc v1.0.0 is available via extras](http://mirror.centos.org/centos/7.4.1708/extras/x86_64/Packages/runc-1.0.0-12.1.gitf8ce01d.el7.x86_64.rpm), so a `yum install runc` should do the trick. i'm not sure about other centos versions or distros.



ä¸€ä¸ªè­¦å‘Šä¿¡æ¯æ˜¯ `crictl not found in system path`ï¼Œå¦ä¸€ä¸ªé”™è¯¯ä¿¡æ¯æ˜¯Â `running with swap on is not supported. Please disable swap`ã€‚å› ä¸ºæˆ‘ä»¬å‰é¢å·²ç»ä¿®æ”¹äº†kubeletçš„å¯åŠ¨å‚æ•°ï¼Œæ‰€ä»¥é‡æ–°æ·»åŠ  `â€“ignore-preflight-errors=Swap` å‚æ•°å¿½ç•¥è¿™ä¸ªé”™è¯¯ï¼Œé‡æ–°è¿è¡Œã€‚æˆ–è€…ä½¿ç”¨ `swapoff -a` ä¸´æ—¶å…¨å±€å…³é—­ï¼Œå¯èƒ½ä¼šå½±å“è¿è¡Œçš„æœåŠ¡ã€‚

```shell
$ kubeadm init   --kubernetes-version=v1.9.1   --pod-network-cidr=10.0.0.0/16   --apiserver-advertise-address=172.16.132.10 --ignore-preflight-errors=Swap
```



é”™è¯¯æ’æŸ¥ï¼š

```shell
$ systemctl status docker.service -l
â— docker.service - Docker Application Container Engine
   Loaded: loaded (/usr/lib/systemd/system/docker.service; enabled; vendor preset: disabled)
   Active: failed (Result: exit-code) since Tue 2018-01-09 17:50:56 CST; 31s ago
     Docs: http://docs.docker.com
  Process: 41393 ExecStart=/usr/bin/dockerd-current --add-runtime docker-runc=/usr/libexec/docker/docker-runc-current --default-runtime=docker-runc --exec-opt native.cgroupdriver=systemd --userland-proxy-path=/usr/libexec/docker/docker-proxy-current $OPTIONS $DOCKER_STORAGE_OPTIONS $DOCKER_NETWORK_OPTIONS $ADD_REGISTRY $BLOCK_REGISTRY $INSECURE_REGISTRY $REGISTRIES (code=exited, status=1/FAILURE)
 Main PID: 41393 (code=exited, status=1/FAILURE)

Jan 09 17:50:56 localhost.localdomain systemd[1]: Starting Docker Application Container Engine...
Jan 09 17:50:56 localhost.localdomain dockerd-current[41393]: time="2018-01-09T17:50:56+08:00" level=fatal msg="unable to configure the Docker daemon with file /etc/docker/daemon.json: the following directives are specified both as a flag and in the configuration file: exec-opts: (from flag: [native.cgroupdriver=systemd], from file: [native.cgroupdriver=systemd])\n"
Jan 09 17:50:56 localhost.localdomain systemd[1]: docker.service: main process exited, code=exited, status=1/FAILURE
Jan 09 17:50:56 localhost.localdomain systemd[1]: Failed to start Docker Application Container Engine.
Jan 09 17:50:56 localhost.localdomain systemd[1]: Unit docker.service entered failed state.
Jan 09 17:50:56 localhost.localdomain systemd[1]: docker.service failed.
```

## 10. æ¶‰åŠåˆ°çš„Imageåˆ—è¡¨

```
gcr.io/google_containers/kube-apiserver-amd64:v1.9.1             210.4 MB
gcr.io/google_containers/kube-scheduler-amd64:v1.9.1             62.7 MB
gcr.io/google_containers/kube-proxy-amd64:v1.9.1                 109.1 MB
gcr.io/google_containers/kube-controller-manager-amd64:v1.9.1    137.8 MB
gcr.io/google_containers/kubernetes-dashboard-amd64:v1.8.1       120.7 MB
quay.io/coreos/flannel:v0.9.1-amd64                              51.31 MB
gcr.io/google_containers/k8s-dns-sidecar-amd64:1.14.7            42.03 MB
gcr.io/google_containers/k8s-dns-kube-dns-amd64:1.14.7           50.27 MB
gcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64:1.14.7      40.95 MB
gcr.io/google_containers/etcd-amd64:3.1.10                       192.7 MB
gcr.io/google_containers/pause-amd64:3.0                         746.9 kB

k8s.gcr.io/heapster-influxdb-amd64:v1.3.3                        12.55 MB
k8s.gcr.io/heapster-grafana-amd64:v4.4.3                         151.5 MB
k8s.gcr.io/heapster-amd64:v1.4.2                                  73.4 MB
docker.io/radial/busyboxplus:curl                                4.212 MB

```



## 11. å‚è€ƒ

1. [ä½¿ç”¨kubeadmå®‰è£…Kubernetes 1.9](https://blog.frognew.com/2017/12/kubeadm-install-kubernetes-1.9.html#7%E5%90%91kubernetes%E9%9B%86%E7%BE%A4%E6%B7%BB%E5%8A%A0node)
2. [kubeadméƒ¨ç½²k8s1.9é«˜å¯ç”¨é›†ç¾¤--4éƒ¨ç½²masterèŠ‚ç‚¹](https://segmentfault.com/a/1190000012559479)
3. [Issues 40969](https://github.com/kubernetes/kubernetes/issues/40969)
4. [Using kubeadm to Create a Cluster](https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/)
5. [Kubernetesé›†ç¾¤Dashboardæ’ä»¶å®‰è£…](http://tonybai.com/2017/01/19/install-dashboard-addon-for-k8s/)
6. [k8s network](https://github.com/kubernetes/community/blob/master/contributors/design-proposals/network/networking.md#toc2)
7. [Cluster Networking](https://kubernetes.io/docs/concepts/cluster-administration/networking/)
8. [Four ways to connect a docker container to a local network](http://blog.oddbit.com/2014/08/11/four-ways-to-connect-a-docker/)
9. [Docker container networking](https://docs.docker.com/engine/userguide/networking/)
10. [Bridge the docker containers to external network](https://developer.ibm.com/recipes/tutorials/bridge-the-docker-containers-to-external-network/)
11. [Docker - Create a Bridge and Shared Network](https://coderwall.com/p/2rpbba/docker-create-a-bridge-and-shared-network)
12. [Build your own bridge](https://docs.docker.com/engine/userguide/networking/default_network/build-bridges/)
13. [Customize the docker0 bridge](https://docs.docker.com/engine/userguide/networking/default_network/custom-docker0/)
14. [CentOS / RHEL 7 : How to disable IPv6](https://www.thegeekdiary.com/centos-rhel-7-how-to-disable-ipv6/)